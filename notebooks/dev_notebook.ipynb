{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "institutional-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "controlling-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/joe/mimic_reader/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fuzzy-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_eligibility_query_prefix(pop_size_string, min_age_string, min_dur_string, max_dur_string, min_day_string):\n",
    "    with open('./queries/eligibility.sql','r') as f:\n",
    "        query_raw = f.read()\n",
    "    query_parsed = query_raw.format(\n",
    "        limit=pop_size_string, min_age=min_age_string, min_dur=min_dur_string, \n",
    "        max_dur=max_dur_string, min_day=min_day_string)\n",
    "    return query_parsed\n",
    "\n",
    "def get_eligibility_query(eligibility_query_prefix):\n",
    "    query = eligibility_query_prefix + \\\n",
    "    \"\"\"\n",
    "    select * from eligible_patients\n",
    "        ;\n",
    "        \"\"\"\n",
    "    return query\n",
    "\n",
    "def get_static_covariates_query(eligibility_query_prefix):\n",
    "    with open('./queries/static_covariates.sql','r') as f:\n",
    "        query_raw = f.read()\n",
    "    query_parsed = eligibility_query_prefix + query_raw # no formatting needed\n",
    "    return query_parsed\n",
    "\n",
    "def get_outcomes_query(eligibility_query_prefix):    \n",
    "    with open(',/queries/outcomes.sql','r') as f:\n",
    "        query_raw = f.read()\n",
    "    query_parsed = eligibility_query_prefix + query_raw # no formatting needed yet\n",
    "    return query_parsed\n",
    "\n",
    "\n",
    "def get_treatment_query(eligibility_query_prefix):\n",
    "    with open('./queries/treatments.sql','r') as f:\n",
    "        query_raw = f.read()\n",
    "    query_parsed = eligibility_query_prefix + query_raw # no formatting needed yet\n",
    "    return query_parsed\n",
    "\n",
    "\n",
    "def get_inputs_query(eligibility_query_prefix):\n",
    "    with open('./queries/inputs_dynamic.sql','r') as f:\n",
    "        query_raw = f.read()\n",
    "    query_parsed = eligibility_query_prefix + query_raw # no formatting needed yet\n",
    "    return query_parsed\n",
    "\n",
    "def get_dynamic_covariates_query(eligibility_query_prefix):#, chartitems_to_keep, labitems_to_keep):\n",
    "    with open('./queries/dynamic_covariates_choose_all.sql','r') as f:\n",
    "        query_raw = f.read()\n",
    "    query_parsed = eligibility_query_prefix + query_raw#.format(\\\n",
    "        #chitem=chartitems_to_keep, lbitem=labitems_to_keep)\n",
    "    return query_parsed\n",
    "\n",
    "def get_useful_chart_lab_itemids(common_chartlabs_filename):\n",
    "    common_ids = pd.read_csv(common_chartlabs_filename)\n",
    "\n",
    "    common_chartevents = common_ids[common_ids['chartorlab'] == 'chart']['itemid']\n",
    "    common_labevents = common_ids[common_ids['chartorlab'] == 'lab']['itemid']\n",
    "\n",
    "    chartitems_to_keep = str(tuple(common_chartevents.values[:200]))\n",
    "    labitems_to_keep = str(tuple(common_labevents.values[:100]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ambient-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_args():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument('--out_path', type=str, default= '../data/curated',\n",
    "                    help='Enter the path you want the output')\n",
    "    ap.add_argument('--resource_path',\n",
    "        type=str,\n",
    "        default=os.path.expandvars(\"$MIMIC_EXTRACT_CODE_DIR/resources/\"))\n",
    "    ap.add_argument('--extract_pop', type=int, default=1,\n",
    "                    help='Whether or not to extract population data: 0 - no extraction, ' +\n",
    "                    '1 - extract if not present in the data directory, 2 - extract even if there is data')\n",
    "\n",
    "    ap.add_argument('--extract_numerics', type=int, default=1,\n",
    "                    help='Whether or not to extract numerics data: 0 - no extraction, ' +\n",
    "                    '1 - extract if not present in the data directory, 2 - extract even if there is data')\n",
    "    ap.add_argument('--extract_outcomes', type=int, default=1,\n",
    "                    help='Whether or not to extract outcome data: 0 - no extraction, ' +\n",
    "                    '1 - extract if not present in the data directory, 2 - extract even if there is data')\n",
    "    ap.add_argument('--extract_codes', type=int, default=1,\n",
    "                    help='Whether or not to extract ICD9 codes: 0 - no extraction, ' +\n",
    "                    '1 - extract if not present in the data directory, 2 - extract even if there is data')\n",
    "    ap.add_argument('--pop_size', type=int, default=-1,\n",
    "                    help='Size of population to extract')\n",
    "    ap.add_argument('--exit_after_loading', type=int, default=0)\n",
    "    ap.add_argument('--var_limits', type=int, default=1,\n",
    "                    help='Whether to create a version of the data with variable limits included. ' +\n",
    "                    '1 - apply variable limits, 0 - do not apply variable limits')\n",
    "    ap.add_argument('--plot_hist', type=int, default=1,\n",
    "                    help='Whether to plot the histograms of the data')\n",
    "    ap.add_argument('--psql_host', type=str, default=None,\n",
    "                    help='Postgres host. Try \"/var/run/postgresql/\" for Unix domain socket errors.')\n",
    "    ap.add_argument('--psql_password', type=str, default=None, help='Postgres password.')\n",
    "    ap.add_argument('--group_by_level2', action='store_false', dest='group_by_level2', default=True,\n",
    "                    help='Do group by level2.')\n",
    "    \n",
    "    ap.add_argument('--min_percent', type=float, default=0.0,\n",
    "                    help='Minimum percentage of row numbers need to be observations for each numeric column.' +\n",
    "                    'min_percent = 1 means columns with more than 99 percent of nan will be removed')\n",
    "    ap.add_argument('--min_age', type=int, default=15,\n",
    "                    help='Minimum age of patients to be included')\n",
    "    ap.add_argument('--min_duration', type=int, default=12,\n",
    "                    help='Minimum hours of stay to be included')\n",
    "    ap.add_argument('--max_duration', type=int, default=240,\n",
    "                    help='Maximum hours of stay to be included')\n",
    "    \n",
    "    #############\n",
    "    # Parse args\n",
    "    args = vars(ap.parse_args())\n",
    "    printargs = False\n",
    "    if printargs:\n",
    "        for key in sorted(args.keys()):\n",
    "            print(key, args[key])\n",
    "\n",
    "#  TODO\n",
    "    #if not isdir(args['resource_path']):\n",
    "    #    raise ValueError(\"Invalid resource_path: %s\" % args['resource_path'])\n",
    "\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "featured-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_variable_limits(df, var_ranges, var_names_index_col='LEVEL2'):\n",
    "    idx_vals        = df[var_names_index_col]\n",
    "    non_null_idx    = ~df['value'].isnull()\n",
    "    var_names       = set(idx_vals)\n",
    "    var_range_names = set(var_ranges.index.values)\n",
    "\n",
    "    for var_name in var_names:\n",
    "        if type(var_name) == float and np.isnan(var_name) or var_name.lower() not in var_range_names:\n",
    "            print(\"No known ranges for %s\" % var_name)\n",
    "            continue\n",
    "        else:\n",
    "            var_name_lower = var_name.lower()\n",
    "\n",
    "        outlier_low_val, outlier_high_val, valid_low_val, valid_high_val = [\n",
    "            var_ranges.loc[var_name_lower, x] for x in ('OUTLIER_LOW','OUTLIER_HIGH','VALID_LOW','VALID_HIGH')\n",
    "        ]\n",
    "\n",
    "        running_idx = non_null_idx & (idx_vals == var_name)\n",
    "\n",
    "        outlier_low_idx  = (df.value < outlier_low_val)\n",
    "        outlier_high_idx = (df.value > outlier_high_val)\n",
    "        valid_low_idx    = ~outlier_low_idx & (df.value < valid_low_val)\n",
    "        valid_high_idx   = ~outlier_high_idx & (df.value > valid_high_val)\n",
    "\n",
    "        var_outlier_idx   = running_idx & (outlier_low_idx | outlier_high_idx)\n",
    "        var_valid_low_idx = running_idx & valid_low_idx\n",
    "        var_valid_high_idx = running_idx & valid_high_idx\n",
    "\n",
    "        df.loc[var_outlier_idx, 'value'] = np.nan\n",
    "        df.loc[var_valid_low_idx, 'value'] = valid_low_val\n",
    "        df.loc[var_valid_high_idx, 'value'] = valid_high_val\n",
    "\n",
    "        n_outlier = sum(var_outlier_idx)\n",
    "        n_valid_low = sum(var_valid_low_idx)\n",
    "        n_valid_high = sum(var_valid_high_idx)\n",
    "        if n_outlier + n_valid_low + n_valid_high > 0:\n",
    "            print(\n",
    "                \"%s had %d / %d rows cleaned:\\n\"\n",
    "                \"  %d rows were strict outliers, set to np.nan\\n\"\n",
    "                \"  %d rows were low valid outliers, set to %.2f\\n\"\n",
    "                \"  %d rows were high valid outliers, set to %.2f\\n\"\n",
    "                \"\" % (\n",
    "                    var_name,\n",
    "                    n_outlier + n_valid_low + n_valid_high, sum(running_idx),\n",
    "                    n_outlier, n_valid_low, valid_low_val, n_valid_high, valid_high_val\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output filenames\n",
    "static_filename = 'static_data.csv'\n",
    "static_columns_filename = 'static_colnames.txt'\n",
    "\n",
    "dynamic_filename = 'vitals_hourly_data.csv'\n",
    "columns_filename = 'vitals_colnames.txt'\n",
    "subjects_filename = 'subjects.npy'\n",
    "times_filename = 'fenceposts.npy'\n",
    "dynamic_hd5_filename = 'vitals_hourly_data.h5'\n",
    "dynamic_hd5_filt_filename = 'all_hourly_data.h5'\n",
    "\n",
    "codes_filename = 'C.npy'\n",
    "codes_hd5_filename = 'C.h5'\n",
    "idx_hd5_filename = 'C_idx.h5'\n",
    "\n",
    "outcome_filename = 'outcomes_hourly_data.csv'\n",
    "outcome_hd5_filename = 'outcomes_hourly_data.h5'\n",
    "outcome_columns_filename = 'outcomes_colnames.txt'\n",
    "\n",
    "# SQL command params\n",
    "dbname = 'mimic'\n",
    "schema_name = 'mimiciii'\n",
    "\n",
    "ID_COLS = ['subject_id', 'hadm_id', 'icustay_id']\n",
    "ITEM_COLS = ['itemid', 'label', 'LEVEL1', 'LEVEL2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "natural-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(args)\n",
    "using_args = False\n",
    "if using_args:\n",
    "    args = get_args()\n",
    "    min_age_string = str(args['min_age'])\n",
    "    min_dur_string = str(args['min_duration'])\n",
    "    max_dur_string = str(args['max_duration'])\n",
    "    min_day_string = str(float(args['min_duration'])/24)\n",
    "    if args['pop_size'] == -1:\n",
    "        pop_size_string = ''\n",
    "    else:\n",
    "        pop_size_string = str(args['pop_size'])\n",
    "    #if args['psql_host'] is not None: query_args['host'] = args['psql_host']\n",
    "    #if args['psql_password'] is not None: query_args['password'] = args['psql_password']\n",
    "else:\n",
    "    min_age_string = '16'\n",
    "    min_dur_string = '12'\n",
    "    max_dur_string = '240'\n",
    "    min_day_string = '0.5'\n",
    "    pop_size_string = ''\n",
    "\n",
    "query_args = {'dbname': dbname}\n",
    "query_args['user'] = 'postgres'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "checked-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligibility_query_prefix = get_eligibility_query_prefix(\n",
    "    pop_size_string, min_age_string, min_dur_string, max_dur_string, min_day_string)\n",
    "static_covariates_query = get_static_covariates_query(eligibility_query_prefix)\n",
    "dynamic_covariates_query = get_dynamic_covariates_query(eligibility_query_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "np.add(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x: int, y: int) -> int:\n",
    "    \n",
    "    \"\"\" Add two numbers\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : int\n",
    "        First integer\n",
    "    y : int\n",
    "        Second integer\n",
    "\n",
    "    Returns\n",
    "    int\n",
    "        Results\n",
    "\n",
    "    \"\"\"\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "with eligible_patients as\n(\nselect distinct i.subject_id, i.hadm_id, i.stay_id, i.intime, i.outtime\n\tFROM `physionet-data.mimic_icu.icustays` i\n\t--INNER JOIN `physionet-data.mimic_core.admissions` admissions ON i.hadm_id = admissions.hadm_id\n\tINNER JOIN `physionet-data.mimic_derived.age` age ON i.hadm_id = age.hadm_id\n\tinner join `physionet-data.mimic_hosp.diagnoses_icd` dx on dx.hadm_id = i.hadm_id\n\twhere\n\t\ti.subject_id >= 40000\n\t\tand age.age >= 18\n\t\tand i.los >= 0.5\n\t\tand i.outtime >= DATETIME_ADD(i.intime, INTERVAL 12 HOUR)\n\t\tand i.outtime <= DATETIME_ADD(i.intime, INTERVAL 240 HOUR)\n\t\t--and icd_code like 'I48%' or icd_code like '42731%' --atrial fibrillation or atrial flutter\n)\nselect *\nfrom eligible_patients ep\nselect distinct ep.subject_id, ep.hadm_id, ep.stay_id\n, g.age\n, a.ethnicity\nFROM eligible_patients ep\n\n\nLEFT JOIN `physionet-data.mimic_derived.age` g on g.hadm_id = ep.hadm_id\nLEFT JOIN `physionet-data.mimic_core.admissions` a ON a.hadm_id = ep.hadm_id\n"
     ]
    }
   ],
   "source": [
    "print(static_covariates_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'eligibility_query_prefix' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c56e141c788c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_inputs_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meligibility_query_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'eligibility_query_prefix' is not defined"
     ]
    }
   ],
   "source": [
    "inputs_query = get_inputs_query(eligibility_query_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vertical-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# used for joining rest of downstream queries\n",
    "eligibility_query_prefix = get_eligibility_query_prefix(\n",
    "    pop_size_string, min_age_string, min_dur_string, max_dur_string, min_day_string)\n",
    "static_covariates_query = get_static_covariates_query(eligibility_query_prefix)\n",
    "\n",
    "#root_dir = '/home/joe/Predict_PO2/new_mimic_cleaner/'\n",
    "#common_chartlabs_fil--INNER JOIN `physionet-data.mimic_core.admissions` admissions ON i.hadm_id = admissions.hadm_idename = root_dir + 'mimic_id_tables/get_common_charts_labs_results_metavision.csv'\n",
    "#chartitems_to_keep, labitems_to_keep = get_useful_chart_lab_itemids(common_chartlabs_filename)\n",
    "\n",
    "#dynamic_query = get_dynamic_covariates_query(eligibility_query_prefix, chartitems_to_keep, labitems_to_keep)\n",
    "\n",
    "inputs_query = get_inputs_query(eligibility_query_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligibility_query_prefix = get_eligibility_query_prefix(\n",
    "    pop_size_string, min_age_string, min_dur_string, max_dur_string, min_day_string)\n",
    "static_covariates_query = get_static_covariates_query(eligibility_query_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "with eligible_patients as\n(\nselect distinct i.subject_id, i.hadm_id, i.stay_id, i.intime, i.outtime\n\tFROM `physionet-data.mimic_icu.icustays` i\n\tINNER JOIN `physionet-data.mimic_core.admissions` a ON i.hadm_id = a.hadm_id\n\tINNER JOIN `physionet-data.mimic_derived.age` g ON i.hadm_id = i.hadm_id\n\twhere\n\t\ti.subject_id >= 40000\n\t\tand g.age >= 18\n\t\tand i.los >= 0.5\n\t\tand i.outtime >= DATETIME_ADD(i.intime, INTERVAL 12 HOUR)\n\t\tand i.outtime <= DATETIME_ADD(i.intime, INTERVAL 240 HOUR)\n)\nselect distinct ep.subject_id, ep.hadm_id, ep.stay_id\n, g.age\n, a.ethnicity\nFROM eligible_patients ep\n\n\nLEFT JOIN `physionet-data.mimic_derived.age` g on g.hadm_id = ep.hadm_id\nLEFT JOIN `physionet-data.mimic_core.admissions` a ON a.hadm_id = ep.hadm_id\n"
     ]
    }
   ],
   "source": [
    "print(static_covariates_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = pydata_google_auth.get_user_credentials(\n",
    "    ['https://www.googleapis.com/auth/cloud-platform'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-01b0aeef305e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpydata_google_auth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_user_credentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'https://www.googleapis.com/auth/cloud-platform'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/pydata_google_auth/auth.py\u001b[0m in \u001b[0;36mget_user_credentials\u001b[0;34m(scopes, client_id, client_secret, credentials_cache, use_local_webserver, auth_local_webserver)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mclient_secret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLIENT_SECRET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcredentials_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     client_config = {\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/pydata_google_auth/cache.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mcredentials\u001b[0m \u001b[0mcould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load_user_credentials_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/pydata_google_auth/cache.py\u001b[0m in \u001b[0;36m_load_user_credentials_from_file\u001b[0;34m(credentials_path)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_load_user_credentials_from_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredentials_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/pydata_google_auth/cache.py\u001b[0m in \u001b[0;36m_load_user_credentials_from_info\u001b[0;34m(credentials_json)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mcredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRefreshError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m# Credentials could be expired or revoked. Try to reauthorize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/google/oauth2/credentials.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client_secret\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scopes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         )\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/google/oauth2/_client.py\u001b[0m in \u001b[0;36mrefresh_grant\u001b[0;34m(request, token_uri, refresh_token, client_id, client_secret, scopes)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mbody\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scope\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscopes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mresponse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_token_endpoint_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/google/oauth2/_client.py\u001b[0m in \u001b[0;36m_token_endpoint_request\u001b[0;34m(request, token_uri, body)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m# occurs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         response_body = (\n\u001b[1;32m    107\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, url, method, body, headers, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Making request: %s %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             response = self.session.request(\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             )\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_Response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             )\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mtls_in_tls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             )\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pydata_google_auth.get_user_credentials(['https://www.googleapis.com/auth/cloud-platform'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-dd361ac9ff41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpydata_google_auth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydata_google_auth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_user_credentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'https://www.googleapis.com/auth/cloud-platform'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbigquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mimic-reader'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/pydata_google_auth/auth.py\u001b[0m in \u001b[0;36mget_user_credentials\u001b[0;34m(scopes, client_id, client_secret, credentials_cache, use_local_webserver, auth_local_webserver)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mclient_secret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLIENT_SECRET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcredentials_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     client_config = {\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/pydata_google_auth/cache.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mcredentials\u001b[0m \u001b[0mcould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load_user_credentials_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/pydata_google_auth/cache.py\u001b[0m in \u001b[0;36m_load_user_credentials_from_file\u001b[0;34m(credentials_path)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_load_user_credentials_from_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredentials_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/pydata_google_auth/cache.py\u001b[0m in \u001b[0;36m_load_user_credentials_from_info\u001b[0;34m(credentials_json)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mcredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRefreshError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m# Credentials could be expired or revoked. Try to reauthorize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/google/oauth2/credentials.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client_secret\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scopes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         )\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/google/oauth2/_client.py\u001b[0m in \u001b[0;36mrefresh_grant\u001b[0;34m(request, token_uri, refresh_token, client_id, client_secret, scopes)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mbody\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scope\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscopes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mresponse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_token_endpoint_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/google/oauth2/_client.py\u001b[0m in \u001b[0;36m_token_endpoint_request\u001b[0;34m(request, token_uri, body)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m# occurs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         response_body = (\n\u001b[1;32m    107\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, url, method, body, headers, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Making request: %s %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             response = self.session.request(\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             )\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_Response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             )\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mtls_in_tls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             )\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mimic_understander/env/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pydata_google_auth\n",
    "credentials = pydata_google_auth.get_user_credentials(['https://www.googleapis.com/auth/cloud-platform'])\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(project='mimic-reader', credentials=credentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = client.query(static_covariates_query)\n",
    "results = query_job.result().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       subject_id   hadm_id   stay_id  age               ethnicity\n",
       "0        18896198  28533642  35852518   27  BLACK/AFRICAN AMERICAN\n",
       "1        16732697  22408115  31923391   31                 UNKNOWN\n",
       "2        19378928  23673648  31355457   90                   WHITE\n",
       "3        10213765  28522861  39765853   20         HISPANIC/LATINO\n",
       "4        18846991  29276122  35526704   93                   WHITE\n",
       "...           ...       ...       ...  ...                     ...\n",
       "61408    13510993  29580307  30187740   92                   WHITE\n",
       "61409    17608704  26416232  34419147   92                   WHITE\n",
       "61410    18344051  27968246  39565849   92                   WHITE\n",
       "61411    10806849  21477011  36491323   92                   WHITE\n",
       "61412    10919141  20409351  36618427   92  BLACK/AFRICAN AMERICAN\n",
       "\n",
       "[61413 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>hadm_id</th>\n      <th>stay_id</th>\n      <th>age</th>\n      <th>ethnicity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18896198</td>\n      <td>28533642</td>\n      <td>35852518</td>\n      <td>27</td>\n      <td>BLACK/AFRICAN AMERICAN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16732697</td>\n      <td>22408115</td>\n      <td>31923391</td>\n      <td>31</td>\n      <td>UNKNOWN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19378928</td>\n      <td>23673648</td>\n      <td>31355457</td>\n      <td>90</td>\n      <td>WHITE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10213765</td>\n      <td>28522861</td>\n      <td>39765853</td>\n      <td>20</td>\n      <td>HISPANIC/LATINO</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18846991</td>\n      <td>29276122</td>\n      <td>35526704</td>\n      <td>93</td>\n      <td>WHITE</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>61408</th>\n      <td>13510993</td>\n      <td>29580307</td>\n      <td>30187740</td>\n      <td>92</td>\n      <td>WHITE</td>\n    </tr>\n    <tr>\n      <th>61409</th>\n      <td>17608704</td>\n      <td>26416232</td>\n      <td>34419147</td>\n      <td>92</td>\n      <td>WHITE</td>\n    </tr>\n    <tr>\n      <th>61410</th>\n      <td>18344051</td>\n      <td>27968246</td>\n      <td>39565849</td>\n      <td>92</td>\n      <td>WHITE</td>\n    </tr>\n    <tr>\n      <th>61411</th>\n      <td>10806849</td>\n      <td>21477011</td>\n      <td>36491323</td>\n      <td>92</td>\n      <td>WHITE</td>\n    </tr>\n    <tr>\n      <th>61412</th>\n      <td>10919141</td>\n      <td>20409351</td>\n      <td>36618427</td>\n      <td>92</td>\n      <td>BLACK/AFRICAN AMERICAN</td>\n    </tr>\n  </tbody>\n</table>\n<p>61413 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "os.path.exists(root_dir + '/data/external/static_vars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "using_args = False\n",
    "if using_args:\n",
    "    args = get_args()\n",
    "    min_age_string = str(args['min_age'])\n",
    "    min_dur_string = str(args['min_duration'])\n",
    "    max_dur_string = str(args['max_duration'])\n",
    "    min_day_string = str(float(args['min_duration'])/24)\n",
    "    if args['pop_size'] == -1:\n",
    "        pop_size_string = ''\n",
    "    else:\n",
    "        pop_size_string = str(args['pop_size'])\n",
    "    #if args['psql_host'] is not None: query_args['host'] = args['psql_host']\n",
    "    #if args['psql_password'] is not None: query_args['password'] = args['psql_password']\n",
    "else:\n",
    "    min_age_string = '16'\n",
    "    min_dur_string = '12'\n",
    "    max_dur_string = '240'\n",
    "    min_day_string = '0.5'\n",
    "    pop_size_string = ''\n",
    "\n",
    "root_dir = '/home/joe/mimic_understander/'\n",
    "\n",
    "# used for joining rest of downstream queries\n",
    "eligibility_query_prefix = get_eligibility_query_prefix(\n",
    "    pop_size_string, min_age_string, min_dur_string, max_dur_string, min_day_string)\n",
    "\n",
    "static_covariates_query = get_static_covariates_query(eligibility_query_prefix)\n",
    "dynamic_query = get_dynamic_covariates_query(eligibility_query_prefix)#, chartitems_to_keep, labitems_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ~os.path.exists(root_dir + './data/processed/static_vars.csv') or reread_data['static']:\n",
    "    query_job = client.query(static_covariates_query)\n",
    "    results = query_job.result().to_dataframe()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = client.query(static_covariates_query)\n",
    "results = query_job.result().to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ~os.path.exists(root_dir + './data/processed/static_vars.csv') or reread_data['static']:\n",
    "    query_job = client.query(static_covariates_query)\n",
    "    results = query_job.result().to_dataframe()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       subject_id   hadm_id   stay_id  age               ethnicity\n",
       "0        18896198  28533642  35852518   27  BLACK/AFRICAN AMERICAN\n",
       "1        16732697  22408115  31923391   31                 UNKNOWN\n",
       "2        19378928  23673648  31355457   90                   WHITE\n",
       "3        10213765  28522861  39765853   20         HISPANIC/LATINO\n",
       "4        18846991  29276122  35526704   93                   WHITE\n",
       "...           ...       ...       ...  ...                     ...\n",
       "61408    13510993  29580307  30187740   92                   WHITE\n",
       "61409    17608704  26416232  34419147   92                   WHITE\n",
       "61410    18344051  27968246  39565849   92                   WHITE\n",
       "61411    10806849  21477011  36491323   92                   WHITE\n",
       "61412    10919141  20409351  36618427   92  BLACK/AFRICAN AMERICAN\n",
       "\n",
       "[61413 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>hadm_id</th>\n      <th>stay_id</th>\n      <th>age</th>\n      <th>ethnicity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18896198</td>\n      <td>28533642</td>\n      <td>35852518</td>\n      <td>27</td>\n      <td>BLACK/AFRICAN AMERICAN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16732697</td>\n      <td>22408115</td>\n      <td>31923391</td>\n      <td>31</td>\n      <td>UNKNOWN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19378928</td>\n      <td>23673648</td>\n      <td>31355457</td>\n      <td>90</td>\n      <td>WHITE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10213765</td>\n      <td>28522861</td>\n      <td>39765853</td>\n      <td>20</td>\n      <td>HISPANIC/LATINO</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18846991</td>\n      <td>29276122</td>\n      <td>35526704</td>\n      <td>93</td>\n      <td>WHITE</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>61408</th>\n      <td>13510993</td>\n      <td>29580307</td>\n      <td>30187740</td>\n      <td>92</td>\n      <td>WHITE</td>\n    </tr>\n    <tr>\n      <th>61409</th>\n      <td>17608704</td>\n      <td>26416232</td>\n      <td>34419147</td>\n      <td>92</td>\n      <td>WHITE</td>\n    </tr>\n    <tr>\n      <th>61410</th>\n      <td>18344051</td>\n      <td>27968246</td>\n      <td>39565849</td>\n      <td>92</td>\n      <td>WHITE</td>\n    </tr>\n    <tr>\n      <th>61411</th>\n      <td>10806849</td>\n      <td>21477011</td>\n      <td>36491323</td>\n      <td>92</td>\n      <td>WHITE</td>\n    </tr>\n    <tr>\n      <th>61412</th>\n      <td>10919141</td>\n      <td>20409351</td>\n      <td>36618427</td>\n      <td>92</td>\n      <td>BLACK/AFRICAN AMERICAN</td>\n    </tr>\n  </tbody>\n</table>\n<p>61413 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "results.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'reread_data' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3c824b66e814>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreread_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'reread_data' is not defined"
     ]
    }
   ],
   "source": [
    "reread_data = {}"
   ]
  },
  {
   "source": [
    "# all other functions\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_values_by_name_from_df_column_or_index(data_df, colname):\n",
    "    \"\"\" Easily get values for named field, whether a column or an index\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    values : 1D array\n",
    "    \"\"\"\n",
    "    try:\n",
    "        values = data_df[colname]\n",
    "    except KeyError as e:\n",
    "        if colname in data_df.index.names:\n",
    "            values = data_df.index.get_level_values(colname)\n",
    "        else:\n",
    "            raise e\n",
    "    return values\n",
    "\n",
    "\n",
    "def add_outcome_indicators(out_gb):\n",
    "    subject_id = out_gb['subject_id'].unique()[0]\n",
    "    hadm_id = out_gb['hadm_id'].unique()[0]\n",
    "    icustay_id = out_gb['icustay_id'].unique()[0]\n",
    "    max_hrs = out_gb['max_hours'].unique()[0]\n",
    "    on_hrs = set()\n",
    "\n",
    "    for index, row in out_gb.iterrows():\n",
    "        on_hrs.update(range(row['starttime'], row['endtime'] + 1))\n",
    "\n",
    "    off_hrs = set(range(max_hrs + 1)) - on_hrs\n",
    "    on_vals = [0]*len(off_hrs) + [1]*len(on_hrs)\n",
    "    hours = list(off_hrs) + list(on_hrs)\n",
    "    return pd.DataFrame({'subject_id': subject_id, 'hadm_id':hadm_id,\n",
    "                        'hours_in':hours, 'on':on_vals}) #icustay_id': icustay_id})\n",
    "\n",
    "\n",
    "def add_blank_indicators(out_gb):\n",
    "    subject_id = out_gb['subject_id'].unique()[0]\n",
    "    hadm_id = out_gb['hadm_id'].unique()[0]\n",
    "    #icustay_id = out_gb['icustay_id'].unique()[0]\n",
    "    max_hrs = out_gb['max_hours'].unique()[0]\n",
    "\n",
    "    hrs = range(max_hrs + 1)\n",
    "    vals = list([0]*len(hrs))\n",
    "    return pd.DataFrame({'subject_id': subject_id, 'hadm_id':hadm_id,\n",
    "                        'hours_in':hrs, 'on':vals})#'icustay_id': icustay_id,\n",
    "\n",
    "\n",
    "def get_variable_mapping(mimic_mapping_filename):\n",
    "    # Read in the second level mapping of the itemids\n",
    "    var_map = pd.read_csv(mimic_mapping_filename, index_col=None).fillna('')#.astype(str)\n",
    "    var_map = var_map.loc[(var_map['LEVEL2'] != '') & (var_map.count(axis='columns')>0)]\n",
    "    var_map = var_map.loc[(var_map.STATUS == 'ready')]\n",
    "    var_map.ITEMID = var_map.ITEMID.astype(int)\n",
    "    return var_map\n",
    "\n",
    "\n",
    "def get_variable_ranges(range_filename):\n",
    "    # Read in the second level mapping of the itemid, and take those values out\n",
    "    columns = [ 'LEVEL2', 'OUTLIER LOW', 'VALID LOW', 'IMPUTE', 'VALID HIGH', 'OUTLIER HIGH' ]\n",
    "    to_rename = dict(zip(columns, [ c.replace(' ', '_') for c in columns ]))\n",
    "    to_rename['LEVEL2'] = 'VARIABLE'\n",
    "    var_ranges = pd.read_csv(range_filename, index_col=None)\n",
    "    var_ranges = var_ranges[columns]\n",
    "    var_ranges.rename(to_rename, axis=1, inplace=True)\n",
    "    var_ranges = var_ranges.drop_duplicates(subset='VARIABLE', keep='first')\n",
    "    var_ranges['VARIABLE'] = var_ranges['VARIABLE'].map(str.lower)\n",
    "    var_ranges.set_index('VARIABLE', inplace=True)\n",
    "    var_ranges = var_ranges.loc[var_ranges.notnull().all(axis=1)]\n",
    "\n",
    "    return var_ranges\n",
    "\n",
    "\n",
    "UNIT_CONVERSIONS = [\n",
    "    ('weight',                   'oz',  None,             lambda x: x/16.*0.45359237),\n",
    "    ('weight',                   'lbs', None,             lambda x: x*0.45359237),\n",
    "    ('fraction inspired oxygen', None,  lambda x: x > 1,  lambda x: x/100.),\n",
    "    ('oxygen saturation',        None,  lambda x: x <= 1, lambda x: x*100.),\n",
    "    ('temperature',              'f',   lambda x: x > 79, lambda x: (x - 32) * 5./9),\n",
    "    ('height',                   'in',  None,             lambda x: x*2.54),\n",
    "]\n",
    "\n",
    "\n",
    "def standardize_units(X, name_col='itemid', unit_col='valueuom', value_col='value', inplace=False):\n",
    "    if not inplace: X = X.copy()\n",
    "    name_col_vals = get_values_by_name_from_df_column_or_index(X, name_col)\n",
    "    unit_col_vals = get_values_by_name_from_df_column_or_index(X, unit_col)\n",
    "\n",
    "    try:\n",
    "        name_col_vals = name_col_vals.str\n",
    "        unit_col_vals = unit_col_vals.str\n",
    "    except:\n",
    "        print(\"Can't call *.str\")\n",
    "        print(name_col_vals)\n",
    "        print(unit_col_vals)\n",
    "        raise\n",
    "\n",
    "    #name_filter, unit_filter = [\n",
    "    #    (lambda n: col.contains(n, case=False, na=False)) for col in (name_col_vals, unit_col_vals)\n",
    "    #]\n",
    "    # TODO(mmd): Why does the above not work, but the below does?\n",
    "    name_filter = lambda n: name_col_vals.contains(n, case=False, na=False)\n",
    "    unit_filter = lambda n: unit_col_vals.contains(n, case=False, na=False)\n",
    "\n",
    "    for name, unit, rng_check_fn, convert_fn in UNIT_CONVERSIONS:\n",
    "        name_filter_idx = name_filter(name)\n",
    "        needs_conversion_filter_idx = name_filter_idx & False\n",
    "\n",
    "        if unit is not None: needs_conversion_filter_idx |= name_filter(unit) | unit_filter(unit)\n",
    "        if rng_check_fn is not None: needs_conversion_filter_idx |= rng_check_fn(X[value_col])\n",
    "\n",
    "        idx = name_filter_idx & needs_conversion_filter_idx\n",
    "\n",
    "        X.loc[idx, value_col] = convert_fn(X[value_col][idx])\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def interpolate_variables(df):\n",
    "    df_copy = df.copy()\n",
    "    df_copy.loc[:, 'hours_in'] = (df_copy['charttime'] - df_copy['intime']).dt.floor('min')\n",
    "\n",
    "    df_pruned = df_copy[ID_COLS + ['label', 'value', 'hours_in']]\n",
    "    #df_pruned.loc[:, 'value'] = df_pruned['value'].astype(np.float32)\n",
    "    df_pruned_indexed = df_pruned.set_index(ID_COLS)\n",
    "    df_pivot = df_pruned_indexed.pivot_table(values='value',columns='label',index=ID_COLS + ['hours_in'], aggfunc='last')\n",
    "\n",
    "    df_filled = df_pivot.reset_index().set_index(ID_COLS + ['hours_in'])\n",
    "    #TODO DOESNT DO ANYTHING TODO\n",
    "    #df_filled_grouped = df_filled.groupby([pd.Grouper(key=idx) for idx in ID_COLS]).resample('H').mean() #upsample to hourly\n",
    "\n",
    "\n",
    "    return df_filled\n",
    "\n",
    "\n",
    "def preprocess_dynamic_covariates(dynamic_covariates_df):\n",
    "    # columns to start: ubject_id hadm_id icustay_id intime outtime charttime itemid value valueuom\n",
    "    # var_map = var_map[['LEVEL2', 'ITEMID', 'LEVEL1']].set_index('ITEMID')\n",
    "\n",
    "    # df = pd.merge(dynamic_covariates_df, var_map, how='left', left_on='label', right_on='LEVEL1')\n",
    "    # df['value'] = pd.to_numeric(df['value'], 'coerce')\n",
    "\n",
    "    # df = standardize_units(df, name_col='LEVEL1', inplace=False)\n",
    "\n",
    "    # df = apply_variable_limits(df, var_ranges, 'LEVEL2')\n",
    "\n",
    "    df = interpolate_variables(dynamic_covariates_df)\n",
    "\n",
    "    return df\n",
    "    \n",
    "def interpolate_input_events(input_events_df):\n",
    "    # in this function: there are two types of inputs, continuous and bolus\n",
    "    ## for the continuous, add the rate over the entire time its given, and upsample to minutely\n",
    "    ## note that some intervals of continuous drug overlap, so sum over those overlapping\n",
    "\n",
    "    ## for the bolus, treat as separate columns and record the amount at a given time\n",
    "    ## determine bolus vs continuous via wehtether rate is missing (-> bolus)\n",
    "\n",
    "    #df = inputs_covariates_pruned.copy()\n",
    "    df = input_events_df.copy()\n",
    "\n",
    "    df_cont = df.loc[~pd.isna(df['rate']), :]\n",
    "    df_bolus = df.loc[pd.isna(df['rate']), :]\n",
    "\n",
    "    df_cont.loc[:, 'starttime_in'] = (df_cont['starttime'] - df_cont['intime']).dt.floor('min')\n",
    "    df_cont.loc[:, 'endtime_in'] = (df_cont['endtime'] - df_cont['intime']).dt.floor('min')\n",
    "    df_cont_pruned = df_cont[ID_COLS + ['rate', 'label', 'starttime_in', 'endtime_in']]\n",
    "    df_pivot = df_cont_pruned.pivot_table(\n",
    "        values='rate', columns='label', index=ID_COLS + ['starttime_in', 'endtime_in'],\n",
    "        aggfunc='last')\n",
    "    #sometimes, there is one start and several stopping times, so use the latest endtime only\n",
    "    df_pivot_groupstarts = df_pivot.reset_index().\\\n",
    "        groupby(by=ID_COLS + ['starttime_in']).last().\\\n",
    "        set_index(['endtime_in'], append=True)\n",
    "\n",
    "    #reset twice gives us a column to use called \"index\" later on when matching intervals\n",
    "    indexed_df = df_pivot_groupstarts.reset_index().reset_index() \n",
    "\n",
    "    # this melts on indexes \"index\" (just 0 through num rows), ID_COLS, and each variable name\n",
    "    melted_df = pd.melt(indexed_df,\n",
    "        id_vars=list(indexed_df.drop(['starttime_in','endtime_in'], axis=1).columns),\n",
    "        value_vars=['starttime_in','endtime_in'],\n",
    "        var_name='startend',value_name='hours_in')\n",
    "\n",
    "    # takes about a minute; fills only within each index; each index identifies a start-end pair\n",
    "    filled_timegroups = melted_df.set_index('hours_in').groupby('index').resample('min').\\\n",
    "        ffill().drop('startend', axis=1)\n",
    "    \n",
    "    # sum overlapping intervals, only group by hours_in and id_cols\n",
    "    summed_timegroups = filled_timegroups.drop('index',axis=1).reset_index().\\\n",
    "        groupby(['hours_in'] + ID_COLS).sum()\n",
    "    df_summed_timegroups_clean = summed_timegroups.drop('index',axis=1).\\\n",
    "        reset_index().set_index(ID_COLS + ['hours_in']).sort_index()\n",
    "\n",
    "    # TODO: merge with interpolate_variables fn\n",
    "    # treat the bolus ins the same way as the chartevents, since they happen at a discrete time\n",
    "    df_bolus.loc[:, 'hours_in'] = (df_bolus['starttime'] - df_bolus['intime']).dt.floor('min')\n",
    "\n",
    "    df_bolus_pruned = df_bolus[ID_COLS + ['label', 'amount', 'hours_in']]\n",
    "\n",
    "    df_bolus_pivot = df_bolus_pruned.pivot_table(\n",
    "        values='amount',columns='label',index=ID_COLS + ['hours_in'], aggfunc='last')\n",
    "\n",
    "    df_bolus_pivot_rename = df_bolus_pivot.copy()\n",
    "    df_bolus_pivot_rename.columns = [colname + '_bolus' for colname in list(df_bolus_pivot.columns)]\n",
    "\n",
    "    return df_summed_timegroups_clean, df_bolus_pivot_rename\n",
    "\n",
    "def preprocess_input_events(input_events_df): #TODO: unify with other preprocessor\n",
    "    input_events_processed = interpolate_input_events(input_events_df)\n",
    "\n",
    "    return input_events_processed\n",
    "\n",
    "def apply_variable_limits(df, var_ranges, var_names_index_col='LEVEL2'):\n",
    "    idx_vals        = df[var_names_index_col]\n",
    "    non_null_idx    = ~df['value'].isnull()\n",
    "    var_names       = set(idx_vals)\n",
    "    var_range_names = set(var_ranges.index.values)\n",
    "\n",
    "    for var_name in var_names:\n",
    "        if type(var_name) == float and np.isnan(var_name) or var_name.lower() not in var_range_names:\n",
    "            print(\"No known ranges for %s\" % var_name)\n",
    "            continue\n",
    "        else:\n",
    "            var_name_lower = var_name.lower()\n",
    "\n",
    "        outlier_low_val, outlier_high_val, valid_low_val, valid_high_val = [\n",
    "            var_ranges.loc[var_name_lower, x] for x in ('OUTLIER_LOW','OUTLIER_HIGH','VALID_LOW','VALID_HIGH')\n",
    "        ]\n",
    "\n",
    "        running_idx = non_null_idx & (idx_vals == var_name)\n",
    "\n",
    "        outlier_low_idx  = (df.value < outlier_low_val)\n",
    "        outlier_high_idx = (df.value > outlier_high_val)\n",
    "        valid_low_idx    = ~outlier_low_idx & (df.value < valid_low_val)\n",
    "        valid_high_idx   = ~outlier_high_idx & (df.value > valid_high_val)\n",
    "\n",
    "        var_outlier_idx   = running_idx & (outlier_low_idx | outlier_high_idx)\n",
    "        var_valid_low_idx = running_idx & valid_low_idx\n",
    "        var_valid_high_idx = running_idx & valid_high_idx\n",
    "\n",
    "        df.loc[var_outlier_idx, 'value'] = np.nan\n",
    "        df.loc[var_valid_low_idx, 'value'] = valid_low_val\n",
    "        df.loc[var_valid_high_idx, 'value'] = valid_high_val\n",
    "\n",
    "        n_outlier = sum(var_outlier_idx)\n",
    "        n_valid_low = sum(var_valid_low_idx)\n",
    "        n_valid_high = sum(var_valid_high_idx)\n",
    "        if n_outlier + n_valid_low + n_valid_high > 0:\n",
    "            print(\n",
    "                \"%s had %d / %d rows cleaned:\\n\"\n",
    "                \"  %d rows were strict outliers, set to np.nan\\n\"\n",
    "                \"  %d rows were low valid outliers, set to %.2f\\n\"\n",
    "                \"  %d rows were high valid outliers, set to %.2f\\n\"\n",
    "                \"\" % (\n",
    "                    var_name,\n",
    "                    n_outlier + n_valid_low + n_valid_high, sum(running_idx),\n",
    "                    n_outlier, n_valid_low, valid_low_val, n_valid_high, valid_high_val\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_args():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument('--out_path', type=str, default= '../data/curated',\n",
    "                    help='Enter the path you want the output')\n",
    "    ap.add_argument('--resource_path',\n",
    "        type=str,\n",
    "        default=os.path.expandvars(\"$MIMIC_EXTRACT_CODE_DIR/resources/\"))\n",
    "    ap.add_argument('--extract_pop', type=int, default=1,\n",
    "                    help='Whether or not to extract population data: 0 - no extraction, ' +\n",
    "                    '1 - extract if not present in the data directory, 2 - extract even if there is data')\n",
    "\n",
    "    ap.add_argument('--extract_numerics', type=int, default=1,\n",
    "                    help='Whether or not to extract numerics data: 0 - no extraction, ' +\n",
    "                    '1 - extract if not present in the data directory, 2 - extract even if there is data')\n",
    "    ap.add_argument('--extract_outcomes', type=int, default=1,\n",
    "                    help='Whether or not to extract outcome data: 0 - no extraction, ' +\n",
    "                    '1 - extract if not present in the data directory, 2 - extract even if there is data')\n",
    "    ap.add_argument('--extract_codes', type=int, default=1,\n",
    "                    help='Whether or not to extract ICD9 codes: 0 - no extraction, ' +\n",
    "                    '1 - extract if not present in the data directory, 2 - extract even if there is data')\n",
    "    ap.add_argument('--pop_size', type=int, default=-1,\n",
    "                    help='Size of population to extract')\n",
    "    ap.add_argument('--exit_after_loading', type=int, default=0)\n",
    "    ap.add_argument('--var_limits', type=int, default=1,\n",
    "                    help='Whether to create a version of the data with variable limits included. ' +\n",
    "                    '1 - apply variable limits, 0 - do not apply variable limits')\n",
    "    ap.add_argument('--plot_hist', type=int, default=1,\n",
    "                    help='Whether to plot the histograms of the data')\n",
    "    ap.add_argument('--psql_host', type=str, default=None,\n",
    "                    help='Postgres host. Try \"/var/run/postgresql/\" for Unix domain socket errors.')\n",
    "    ap.add_argument('--psql_password', type=str, default=None, help='Postgres password.')\n",
    "    ap.add_argument('--group_by_level2', action='store_false', dest='group_by_level2', default=True,\n",
    "                    help='Do group by level2.')\n",
    "    \n",
    "    ap.add_argument('--min_percent', type=float, default=0.0,\n",
    "                    help='Minimum percentage of row numbers need to be observations for each numeric column.' +\n",
    "                    'min_percent = 1 means columns with more than 99 percent of nan will be removed')\n",
    "    ap.add_argument('--min_age', type=int, default=15,\n",
    "                    help='Minimum age of patients to be included')\n",
    "    ap.add_argument('--min_duration', type=int, default=12,\n",
    "                    help='Minimum hours of stay to be included')\n",
    "    ap.add_argument('--max_duration', type=int, default=240,\n",
    "                    help='Maximum hours of stay to be included')\n",
    "    \n",
    "    #############\n",
    "    # Parse args\n",
    "    args = vars(ap.parse_args())\n",
    "    printargs = False\n",
    "    if printargs:\n",
    "        for key in sorted(args.keys()):\n",
    "            print(key, args[key])\n",
    "\n",
    "#  TODO\n",
    "    #if not isdir(args['resource_path']):\n",
    "    #    raise ValueError(\"Invalid resource_path: %s\" % args['resource_path'])\n",
    "\n",
    "\n",
    "    return args\n",
    "\n",
    "def get_eligibility_query_prefix(pop_size_string, min_age_string, min_dur_string, max_dur_string, min_day_string):\n",
    "    with open('./src/queries/eligibility.sql','r') as f:\n",
    "        query_raw = f.read()\n",
    "    query_parsed = query_raw.format(\n",
    "        limit=pop_size_string, min_age=min_age_string, min_dur=min_dur_string, \n",
    "        max_dur=max_dur_string, min_day=min_day_string)\n",
    "    return query_parsed\n",
    "\n",
    "def get_eligibility_query(eligibility_query_prefix):\n",
    "    query = eligibility_query_prefix + \\\n",
    "    \"\"\"\n",
    "    select * from eligible_patients\n",
    "        ;\n",
    "        \"\"\"\n",
    "    return query\n",
    "\n",
    "def get_static_covariates_query(eligibility_query_prefix):\n",
    "    with open('./src/queries/static_covariates.sql','r') as f:\n",
    "        query_raw = f.read()\n",
    "    query_parsed = eligibility_query_prefix + query_raw # no formatting needed\n",
    "    return query_parsed\n",
    "\n",
    "def get_outcomes_query(eligibility_query_prefix):    \n",
    "    with open(',/queries/outcomes.sql','r') as f:\n",
    "        query_raw = f.read()\n",
    "    query_parsed = eligibility_query_prefix + query_raw # no formatting needed yet\n",
    "    return query_parsed\n",
    "\n",
    "def get_treatment_query(eligibility_query_prefix):\n",
    "    with open('./queries/treatments.sql','r') as f:\n",
    "        query_raw = f.read()\n",
    "    query_parsed = eligibility_query_prefix + query_raw # no formatting needed yet\n",
    "    return query_parsed\n",
    "\n",
    "def get_inputs_query(eligibility_query_prefix):\n",
    "    with open('./queries/inputs_dynamic.sql','r') as f:\n",
    "        query_raw = f.read()\n",
    "    query_parsed = eligibility_query_prefix + query_raw # no formatting needed yet\n",
    "    return query_parsed\n",
    "\n",
    "def get_dynamic_covariates_query(eligibility_query_prefix):#, chartitems_to_keep, labitems_to_keep):\n",
    "    with open('./src/queries/dynamic_covariates_choose_all.sql','r') as f:\n",
    "        query_raw = f.read()\n",
    "    query_parsed = eligibility_query_prefix + query_raw#.format(\\\n",
    "        #chitem=chartitems_to_keep, lbitem=labitems_to_keep)\n",
    "    return query_parsed\n",
    "\n",
    "def get_useful_chart_lab_itemids(common_chartlabs_filename):\n",
    "    common_ids = pd.read_csv(common_chartlabs_filename)\n",
    "\n",
    "    common_chartevents = common_ids[common_ids['chartorlab'] == 'chart']['itemid']\n",
    "    common_labevents = common_ids[common_ids['chartorlab'] == 'lab']['itemid']\n",
    "\n",
    "    chartitems_to_keep = str(tuple(common_chartevents.values[:200]))\n",
    "    labitems_to_keep = str(tuple(common_labevents.values[:100]))\n",
    "\n",
    "    return chartitems_to_keep, labitems_to_keep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit ('env')",
   "metadata": {
    "interpreter": {
     "hash": "2353d072c5cfafc374ad3ac9dac92f0f5cfafaca6cd96a1a8f57d97e82671bec"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}